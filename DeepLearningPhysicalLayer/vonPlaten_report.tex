\documentclass[twoside,11pt,a4paper,english]{article}

% packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx,curves,float,rotating}

\usepackage{amsmath, amssymb, latexsym}  % math stuff
\usepackage{amsopn}                             % um mathe operatoren zu deklarieren
\usepackage[english]{babel}                     % otherwise use british or american
\usepackage{theorem}                            % instead of \usepackage{amsthm}
\usepackage{dcolumn}
\usepackage{hyperref}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{accents}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}




% @ environment %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xspace}                             % context sensitive space after macros
\makeatletter 
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\eg{{e.g}\onedot} \def\Eg{{E.g}\onedot}
\def\ie{{i.e}\onedot} \def\Ie{{I.e}\onedot}
\def\cf{{c.f}\onedot} \def\Cf{{C.f}\onedot}
\def\etc{{etc}\onedot} \def\vs{{vs}\onedot} 
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{{et al}\onedot}
\def\zB{z.B\onedot} \def\ZB{Z.B\onedot}
\def\dh{d.h\onedot} \def\Dh{D.h\onedot}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%	Macros fuer neue Umgebungen
  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand*{\Frac}[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\newlength{\textwd}
\newlength{\oddsidemargintmp}
\newlength{\evensidemargintmp}
\newcommand*{\hspaceof}[2]{\settowidth{\textwd}{#1}\mbox{\hspace{#2\textwd}}}
\newlength{\textht}
\newcommand*{\vspaceof}[3]{\settoheight{\textht}{#1}\mbox{\raisebox{#2\textht}{#3}}}
\newcommand*{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}

\newenvironment{deflist}[1][\quad]%
{  \begin{list}{}{%
      \renewcommand{\makelabel}[1]{\textbf{##1}\hfil}%
      \settowidth{\labelwidth}{\textbf{#1}}%
      \setlength{\leftmargin}{\labelwidth}
      \addtolength{\leftmargin}{\labelsep}}}
{  \end{list}}


\newenvironment{Quote}% Definition of Quote
{  \begin{list}{}{%
      \setlength{\rightmargin}{0pt}}
      \item[]\ignorespaces}
{\unskip\end{list}}


\theoremstyle{break}
\theorembodyfont{\itshape}	
\theoremheaderfont{\scshape}

\newtheorem{Cor}{Corollary}
\newtheorem{Def}{Definition}
%\newtheorem{Def}[Cor]{Definition}



\newcolumntype{.}{D{.}{.}{-1}}


\pagestyle{headings}
\textwidth 15cm
\textheight 23cm
\oddsidemargin 1cm
\evensidemargin 0cm
%\parindent 0mm



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%       Jetzt geht's los
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%               Title
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{empty}

\begin{center}

    Rheinisch-Westf\"alische Technische Hochschule Aachen \\
    Institute for Theoretical Information Technology \\
    Univ.-Prof. Dr. rer. nat. Rudolf Mathar \\[6ex]
    Seminar on Deep Learning - Methodologies and Applications - SS2018\\[12ex]                          % auch Seminar Titel und Datum ändern!!!
   
    \LARGE
    \textbf{Deep Learning for the Physical Layer} \\[6ex]
    \textit{Patrick von Platen} \\[6ex]
    \Large
    Matrikelnummer 331 430 \\[6ex]
    Datum des Vortrages

    \vfill
    \Large Betreuer: Johannes Schmitz 
	    
\end{center}

\newpage
\ 
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%               Inhaltsverzeichnis / Tabellenverzeichnis / Abbildungsverz.
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{headings}
\tableofcontents
\listoftables
\listoffigures
\newpage
\pagestyle{empty}
\ 
\newpage
\pagestyle{headings}

\section{Motivation}%
\label{sec:motivation}

The physical layer in communication systems defines the means of reliably transmitting 
data over a physical link (called \emph{channel}) connecting network nodes.
Since communications is a complex and mature engineering field, large performance 
improvements, especially in the physical layer, have become rare \cite{DBLP:journals/corr/OSheaH17}.

One of the guiding principles of communication system design is to divide the signal processing into a chain
of multiple independent blocks as can be seen in \ref{fig:BlockCommunicationSystem}. 
Each block (e.g., source/channel coding, modulation, equalization) executes a well defined and isolated function. 
Although this approach has led to the efficient, versatile, and controllable systems we have today, it is not clear that individually optimized processing
blocks achieve the best possible end-to-end performance \cite{DBLP:journals/corr/OSheaH17}.
Today, it is known that the separation of communicaton system design into multiple 
individual blocks is \emph{sub-optimal} for many practical 
channels \cite{141453,504941}.

The continuous rise of deep learning in other fields and possible performance 
improvments motivated researchers, such as \emph{T. J. O'Shea}, to apply artificial neural networks to model end-to-end communication systems using autoencoders \ref{sub:autoencoder}. 

In this report, we want to study how conventional systems of the physical layer can 
be modelled by autoencoders. 
In section \ref{sec:communication_systems}, we will introduce the conventional
communication systems. Then we will give an overview of the most important deep learning 
methods \ref{sec:deep_learning_basics}, that are used to model end-to-end systems 
using autoencoders. 
Two of these systems, one having a closed analytical form by modelling the channel as gaussian 
noise, the other one having a open analytical form using generative adversarial networks \ref{sub:generative_adversarial_networks} to model an unknown channel response will be studied in detail in section 
\ref{sec:applying_deep_learning_to_communication_systems}. 
Finally a conclusion will be drawn \ref{sec:conclusion}.

\section{Conventional Communication Systems} 
\label{sec:communication_systems}

This section aims to explain what the so-called physical layer is actually composed of 
by describing its structure in detail. Later in this section, an example system will be explained and used for performance comparasion with communcation systems applying deep learning methods \ref{sec:applying_deep_learning_to_communication_systems}.

In this report, we use the word \emph{communication system} as the \emph{Physical Layer} of the well-known \emph{OSI Model} as a \emph{communication system}.
As it is defined in \cite{osimodel}, ``the physical layer manages the reception and transmission of the unstructured raw bit stream over a physical medium''. 
The physical layer therefore comprises transforming the raw bit stream to electromagnetic waves that will be transmitted by an antenna at the transmitter, receiving the 
electromagnetic waves via an antenna at the receiver and using them to recover the raw bit stream. 
In the following the connection between the antenna of the transmitter and the antenna of
the receiver will be defined as the \emph{channel}.

\subsection{Structure of the Communication System}%
\label{sub:structure_of_the_communication_system}

The role of the communication system is two-fold:

\begin{itemize}
	\item Efficient Transmitting: The raw bit stream should be converted in such a 
		way that it can be transmitted at a high bit rate in terms of the \emph{Shannon information theory} \cite{Shannon:2001:MTC:584091.584093}
	\item Reliable Delivery: In case of errors due to noise in the channel, the 
		communication system must be able to do error detection and error correction. 
\end{itemize}

This can be achieved by applying sophisticated encoding and decoding schemes also just called ``codes'' to the raw bit stream. Such a ``code'' would for example be the so-called
``Turbo-Code'' \cite{Berrou93nearshannon} that use a special encoding and decoding scheme to reach ``near Shannon limit error-correcting coding and decoding'' meaning that the 
maximum rate at which information can be transmitted over a channel of a specified 
bandwidth in the presence of noise, being the \emph{Shannon rate}, can nearly be archieved while the methods allow for error correction.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.8\linewidth]{images/CommunicationSystem.png}
	\caption{Block Diagram Communication System}
	\label{fig:BlockCommunicationSystem}
\end{figure}

The figure above \ref{fig:BlockCommunicationSystem} describes the 
traditional structure of communication systems. 
We divide the communication system into three parts being the \emph{transmitter,
the channel and the receiver}.
We define all blocks leading to the physical channel to be part of the transmitter, 
including the \emph{source encoder, the channel encoder and the modulator}. The channel, 
called the ``physical channel'' in \ref{fig:BlockCommunicationSystem}, is considered as a separate part, and lastly the following parts \emph{equilizer/demodulator, channel decoder and the source decoder} are part of the receiver. 
In the following, in every part it is shortly explained which transformations are 
applied to the raw bit stream in conventional systems to better understand how \emph{deep
learning methods} can be used to replace them \ref{sec:applying_deep_learning_to_communication_systems}. A more detailed explanation is out of scope for this report. 

\subsubsection{Transmitter}

First, in the block \emph{source encoding}, the raw bit stream $x(k)$ is encoded to
reduce redundancy. 
For this, a source coding scheme is used that defines both how to encode and decode 
a set of symbols $S$ with $x(k) \in S$.

Assuming for example that every symbol in $x(k)$ has the same bit 
length, source coding makes sure that symbols that appear with a higher probability 
are encoded to a more efficent presentation containing less bits whereas 
symbols appearing with a low probability are encoded to symbols made up of more bits.
This way, the overall average \emph{bit rate} can be optimized. There are multiple 
procedures, like \emph{Run-length encoding, Huffman encoding, arithmetic coding,...} from which we can choose from. 
Depending on the coding scheme, both the transmitter and the receiver must know which coding scheme is used.

Second, in the block \emph{channel encoding}, the efficient source code presentation $\ubar{X} \in A$ with $A$ being the set of all possible source encoded symbols is now transformed to a more error robust presentation by adding redundant bits.
There are mainly two procedures for channel coding:

\begin{itemize}
	\item Forward error control: information bits are protected against errors by the transmitting of extra redundant bits, so that if errors occur during transmission the redundant bits can be used by the decoder to determine where the errors have occurred and how to correct them.
	\item Automatic repeat request: In this method redundant bits are added to the transmitted information and are used by the receiver to detect errors. The receiver then signals a request for a repeat transmission.
\end{itemize}

Some well known procedures are \emph{Hamming code, Convolutional encoding, Turbo-Code,...}
Again, in order to succesfully apply these channel coding schemes, both the transmitter 
and the receiver must know which method is used.

Most coding procedures transform the set of symbols $A$ into a code set $M$ having $|M|$ 
entries, whereas $|M| = 2^{k}$ is a power of two so that exactly $k$ bits are needed to 
transmit one symbol.

Lastly, the channel encoded symbols $\ubar{Y}$ are modulated into a carrier wave 
to be transmitted over the \emph{channel}. Since the channel is always bandlimited to 
a certain range of frequency, the signal needs to be transmitted using a carrier that 
is in that range of frequency. 
There are three basic modulation schemes:

\begin{itemize}
	\item Frequency modulation
	\item Amplitude modulation
	\item Phase modulation
\end{itemize}

A signal has three basic properties at every time $t$: frequency, amplitude and phase.
So, information can be modulated into a carrier wave by one, or more of this properties 
to represent the information to be transmitted. 

In this report, we will concentrate on an advanced method, called \emph{quadrature amplitude modulation}.
In quadrature amplitude modulation, two symbols $\ubar{Y}_1$ and $\ubar{Y}_2$ are modulated into the 
amplitude values of two carrier waves having the same frequency, but that are phase-shifted by $\pi/2$.
These two symbols $\ubar{Y}_1$ and $\ubar{Y}_2$ are then called \emph{I/Q symbols} 
and will be inserted for $I(t)$ and $Q(t)$ respectevily into the carrier wave $s_c(t)$, 
such as:

\begin{equation} \label{eq:iq_equation}
	s_c(t) = \Re((I(t) + iQ(t))e^{-2i \pi f_0 t}) = I(t)\cos{2 \pi f_0 t} - Q(t)\sin{2 \pi f_0 t}
\end{equation}

Using some trigometric identities, we can also write:

\begin{equation} \label{eq:ampPhase_equation}
	s_c(t) = \Re(A(t)e^{-2i \pi f_0 t + \varphi(t)i}) = \Re(A(t)i\sin(\varphi(t)) +
	A(t)\cos(\varphi(t)))
\end{equation}

with $I(t) = A(t)\cos(\varphi(t))$ being $Q(t) = A(t)i\sin(\varphi(t))$.

So essentially \emph{quadrature amplitude modulation} can also be viewed as 
just changing the phase and the amplitude of the carrier signal at the same time. 

In practise, when receiving a ``quadrature amplitude modulated'' signal it is 
demodulated to its $Q(t)$ and $I(t)$ values. 

Thus having a code set $M$ of length $|M|=2^k$, needs $|M|$ differnt \emph{I/Q symbols}.
combinations. Having defined $|I|$ distinct values $I$ and $|Q|$ distinct values $Q$, the equation $|Q| \times |I| \ge m$ must hold true.
Each code symbol $m \in M$ can then be represented by a $(Q,I)$ point in the complex plane. Figure \ref{fig:16QAM}
presents such a scheme with $m=16, |Q| = 4, |I| = 4$ which can viewed as a complex 
plane with the $|Q|$ values in the complex y-Axis and the $|I|$ values in the x-Axis.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.5\linewidth]{images/16QAM.png}
	\caption{Example of QAM modulation scheme: M = 16}
	\label{fig:16QAM}
\end{figure}

It can be seen that the arrangement of the points in the grid aims at being equally
spaced in a way that maximizes the euclidean distance between each point and an assumption about the noise in the channel 
having gaussian properties. 
The are multiple other modulation schemes each aiming at finding the most efficient and 
error resistant way to modulate information into a signal considering the probabilistic 
characteristics of the noise in channel.

In section \ref{sec:applying_deep_learning_to_communication_systems}, we will see that autoencoders can automatically learn efficient arrangements that depend not only on the 
probabilistic characteristics of the ``channel layer'', but also on the layers encoding and decoding the 
source symbols being the ``transmitter neural network'' and ``receiver neural network'' (see \ref{sec:applying_deep_learning_to_communication_systems}).

\subsubsection{Channel}
 
The carrier wave $u(t)$ into which the information is modulated into, is then transmitted 
through the channel. It is important to note that, this part of the communication system
is the only part, where the outcome is not deterministic. 
By sending the carrier wave through air as it is done in terrestrial communication 
systems, other signals interfer with the carrier wave and might disrupt its inherent 
information. This is almost always modelled with gaussian noise being added to the 
carrier wave $v(t) = u(t) + r(t)$ with $r(t)$ representing the noise and interference in 
\ref{fig:BlockCommunicationSystem}.

Modelling the channel will later play an important part when applying \emph{deep learning}
methods to realize a communication system \ref{sec:applying_deep_learning_to_communication_systems}

\subsubsection{Receiver}

The receiver will receive $v(t)$, inherently having a probabilistic nature due to the added gaussian noise.
The demodulator then extracts the information of the carrier wave $v(t)$ using 
the predefined values the information was modulated into (the I/Q values 
if using quadrature amplitude modulation). 
This is done by simply sampling the carrier wave at precise time instances $t$ and 
``reading'' the I/Q values from the carrier wave. Finding the exact time 
instances at which the carrier wave should be sampled is known as the synchronization 
problem. Multiple procedures exist with two famous ones being presented in the 
following:

\begin{itemize}
	\item Pilot signal: A signal $i^{*}(t)$ (the pilot signal) is sent with $u(t)$ that 
	      can easily be recognized by the receiver and indicates that the useful information
	      is about to be received and should be sampled. 
	\item Phase-locked loop: A control systems that generates an output signal 
	      whose phase is related to the predefined phase values representing the 
	      different phase-amplitude combinations used to represent the set of codes 
	      $\ubar{Y}$.
\end{itemize}

We will revisit the synchronization problem when applying \emph{deep learning}
methods to realize a communication system \ref{sub:synchronization_problem_when_using_artificial_neural_networks}.

The demodulated stream of information $\ubar{Z}$ will most 
likely contain some errors due to the probable interference in the channel.
But having added redundant information using a channel encoding scheme, we can now use 
the scheme to correct possible errors, which include methods such as \emph{minimum 
distance decoding, syndrome decoding, maximum Likelihood Decoding,...}.
The exact working goes too deep into coding theory which is not of big importance in 
this report, but can easily be read up on in common coding literature.
Depending on the channel coding methods that was chosen, a good estimate of the 
original information $\ubar{\hat{X}}$ can be retrieved.
Finally, inverting the source encoding scheme, we can decode $\ubar{\hat{X}}$ to get 
$\hat{x}(t)$.

\subsection{Convential System Design}

As already stated in \ref{sec:motivation}, conventional communication systems use 
a chain of blocks each being individually chosen and optimized. 

The chosen method for the first block - source encoding - strongly depends on the proberties of the set of symbols the information consists of. Thus, this method is often dynamically changed depending on what information is to be sent.
Channel encoding and modulation design is much more dependent on the given channel 
properties. Especially, the trade-off between wanted error resilience and wanted efficiency in terms of its average codeword length (number of bits), greatly influences
the methods to be used in channel encoding and modulation. 

A Hamming (7,4) code for example, encodes four bits of data into seven bits for error resiliance. 
Doing so, the \emph{Hammming algorithm} can correct any single-bit error, or detect all single-bit and two-bit errors.

\section{Deep Learning Basics}%
\label{sec:deep_learning_basics}

This section aims at introducing the reader to the most important concepts of 
deep learning and how they can be applied to model communication systems.

\subsection{Deep Neural Network}%
\label{sub:deep_neural_network}

Deep neural networks are the essential building blocks in deep learning. 
They are very powerful mathematical models which map some input $x$ to an 
output $f_{\theta}(x)$ by learning parameters $\theta$. 
In other words, they find parameters $\theta$ such that $f_{\theta}(x)$ is the best 
approximation of some function $f^¿$ \cite{Goodfellow-et-al-2016}. 
This function can describe many real-world tasks, e.g. classification of objects on a 
image, transcription of a spoken sentence or translation of a written sequence. 
The approximation power of deep neural networks is the reason for their current success in a
variety of different applications.

Deep neural networks compose together many different functions (called neurons, nodes or units) in a directed acyclic graph manner. Output of each unit $y_j$ can be represented as a weighted sum of $N$ input units $x_i$ followed by a non-linear function $g$:
\[
	y_j =g(\sum_{i=1}^N x_i w_{j,i}+b_j),
\]
where $b_j$ is the bias term leading to the output node $y_j$ and $w_{j,i}$ is weight 
connecting the input node $x_i$ to the output node $y_j$.
Inside deep neural networks, information flows only in one direction, from the input $x$ 
through hidden units to the output $f_{\theta}(x)$ without any loops. 
Hidden units in the network are organized in layers. Stacking more layers results in more abstract, high-level representations of the input data. 
The adjective ``deep'' symbolizes the ability of deep neural networks to 
``learn'' functions of increasing complexity by adding more layers to the network.

The so-called ``learning'' of deep neural networks $f_{\theta}$ refers to the optimizationof its parameters $\theta$ to learn a certain function. 
This is done, by defining a loss or cost function $L(y^{*},\hat{y} = f_{\theta}(x)) \in \mathbb{R}$.
In deep learning, training data is defined as a tuple $(x,y^{*})$ with the input data $x$
and its corresponding label $y^{*}$. The goal in the ``training'' procedure is 
then to find parameters $\theta$ that minimize the loss function $L$:
\[
	\text{argmin}_{\theta} L(y^{*},\hat{y}),
\]
for the training data by minimizing the differenc between $\hat{y}$ and $y^{*}$. 
Due to the high number of non-linear activation functions in a deep neural networks,
this optimization problem is almost always a non-convex problem, thus making it 
impossible to find an analytical solution for $\theta$.
Therefore, in training algorithms like \emph{gradient descent}
are used trying to find a ``good'' local optimum \cite{Goodfellow-et-al-2016}.

Since encoding raw data to a more error resiliant and efficient form is essentially a 
mapping $s: d \to d^*$, deep neural networks can be learned to approximate such 
a function $s$.

\subsection{Autoencoder}%
\label{sub:autoencoder}

An autoencoder is an artificial neural network that maps original data to reconstructed data obtained from 
a hidden representation. It contains a hidden layer $h$ (also denoted as coding or code 
layer) which describes an efficient coding of the input data $x$: $h = f(x)$. The function 
$h$ is called an encoder function and is trained to capture useful properties of the data.
The second part of an autoencoder is a decoder function $r = g(h)$ that aims to reconstruct
the original data. However, perfect reconstruction of the dataset is not the goal of the
autoencoder network. On the contrary, it is trained to be unable to just copy the input 
to output, but to extract useful information about data distribution instead \cite{Goodfellow-et-al-2016}.
Figure \ref{fig:autoencoder1} presents a compact view of an autoencoder.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.2\linewidth]{images/autoencoder1.png}
	\caption{Structure of an autoencoder}
	\label{fig:autoencoder1}
\end{figure}

Autoencoders have been studied extensively in the literature in the recent years.
Several ways were proposed to obtain useful representations in a hidden layer $h$. 
One possible solution is to restrict the coding to have smaller dimension than the
original data. This type of autoencoder is called undercomplete. It learns a 
low-dimensional manifold that represents the principal sub-space of the training data. 

However, when the complexity of encoder and decoder functions is high, undercomplete 
autoencoders fail to learn salient features of the data and just perform useless identity function. To overcome this problem another family of models - regularized autoencoders - were developed. They provide the ability to choose the coding dimension and model flexibility with respect to complexity of the given data.
One of the most popular regularized autoencoders is the sparse autoencoder. It introduces a sparsity penalty $P(h)$ on the hidden layer $h$ that forces a model to learn unique 
statistical properties of the dataset in addition to an identity function. Training criterion of a sparse autoencoder will thus include both reconstruction error and sparsity
penalty:

\[
 L(x,g(f(x)))+P(h)	
\] 

Another way to force an autoencoder to learn useful features is to directly change the
reconstruction error. Denoising autoencoders minimize the objective function:

\[
	L(x, g(f(\widetilde{x}))
\]

where the input to the network $\widetilde{x}$ is a copy of the original input $x$ corrupted by noise. 
The goal of the autoencoder is therefore to recover the original input data from the corrupted signal. 
To achieve this goal denoising autoencoders implicitly learn underlying structure of the data distribution.

The relation to communication systems as they were defined in \ref{sub:structure_of_the_communication_system} is obvious: The blocks belonging to the transmitter are modeled by 
the encoder function $f: x \to h$ and the blocks belonging to the receiver are modeled 
by the decoder function $g: h \to r$. Since the output of the last encoded layer of the transmitter model $h$ presents the actual bit structure to be sent over the network, some kind of corruption or distortian has to be applied to the 
hidden layer $h$ modelling 
the probabilistic nature of the real channel \cite{synch1, DBLP:journals/corr/OSheaH17}.
Therefore, an autoencoder applied for the physical layer would have $f: x \to h$ as 
the encoding function of the transmitter network and $g: \widetilde{h} \to r$ (with $\widetilde{h}$ being a corrupted/distorted version of $h$) as the decoding function of 
the receiver network. The transformation $c: h \to \widetilde{h}$ represents the 
channel network and imitiate the behavior of a ``real'' channel.
Figure \ref{fig:communicationSystemAsAutoencoder} presents an example of such a model.

\subsection{Generative Adversarial Networks}%
\label{sub:generative_adversarial_networks}

Generative adversarial networks belong to the class of generative models and are
based on differentiable generator networks \cite{Goodfellow-et-al-2016}.
Generative adversarial networks basically consists of two networks: 
\begin{itemize}
	\item The generator network: $g_{\theta^{(g)}}: z \to x_{f}: x_{f},z \in \mathbb{R}$
	\item The discriminator network: $d_{\theta^{(d)}}: x \to p: p \in \left[0,1\right], x \in \mathbb{R}$
\end{itemize}

The idea of generative adversarial networks is based on a game theoretic scenario in 
which the \emph{generator} $g_{\theta^{(g)}}$ network must compete against its adversary, the discriminator $d_{\theta^{(d)}}$ network.

The generator network takes random values $z$ as an input to produce ``fake data'' $x_{f}$.
The discriminator takes this ``fake data'' $x_f$ or real data $x_r$ as the input $x$ and emits a 
probability value $p$ indicating whether the data is a real training example or not.

Having this setup, the goal of the generator is to produce data that will be 
evaluated as real data by the discriminator, while the goal of the discriminator 
is to distinguish the ``fake data'' produced by the generator from the real 
training examples. 

Learning in generative adversarial networks can best be described 
as a \emph{zero-sum game}, being continious situations in which each networks pay-off (or loss
function) is exactly balanced by the pay-off of the utility of the other network.

Generative Adversarial Networks comprise multiple different approaches and can have 
multiple interpretations \cite{Goodfellow-et-al-2016}, but the ``standard version'' is as follows:
It consits of alternatively training $g_{\theta^{(g)}}(z) = x_f$ to be similar to $x_r$ and $d_{\theta^{(d)}}(x) = p$ to be close to 1 for $x=x_r$ and close to 0 for $x=x_f$.
This training leads to the 
generator generating data that is more and more similar to real training examples.
Putting in mathematically, we define a pay-off $v_{\theta^{(g)},\theta^{(d)}}$ which
the discriminator tries to maximize and the generator to minimize.
The form of the pay-off $v_{\theta^{(g)},\theta^{(d)}}$ again strongly depends on the 
model, but is often of the form:
\[
	v_{\theta^{(g)},\theta^{(d)}} = \mathbb{E}_{x_r}\log (d_{\theta^{(d)}}(x_r)) + \mathbb{E}_{x_f} \log (1 - d_{\theta^{(d)}}(x_f))
\]
which can also be written as:
\[
	v_{\theta^{(g)},\theta^{(d)}} = \mathbb{E}_{x_r} \log (d_{\theta^{(d)}}(x_r)) + \mathbb{E}_{z} \log (1 - d_{\theta^{(d)}}(g_{\theta^{(g)}}(z)))
\]

Since our final goal is to have a generator function that is able to produce 
data being indistinguishable from real training data, we define $\theta^{(g^{*})}$:
\[
	\theta^{(g^{*})} = \text{argmax}_{\theta^{(g)}} max_{\theta^{(d)}} v_{\theta^{(g)},\theta^{(d)}}
\]

At convergence, the discriminator has to output $p=\frac{1}{2}, \forall x \in \{x_r,x_f\}$.

Unfortunately, training general adversial networks can be quite difficult. 
As stated in \cite{Goodfellow-et-al-2016}, convergence in a \emph{zero-sum game} (or minmax game) is not a local optimum in $v_{\theta^{(g)},\theta^{(d)}}$, but ``are simultaneously minima for both networks' costs''.
These points are saddle points in $v_{\theta^{(g)},\theta^{(d)}}$ being 
local minima with respect to the first network parameters and maxima with respect to 
the second network's parameters. 
Multiple approaches have been realized trying to overcome this problem, that 
can be read up on \cite{Goodfellow-et-al-2016}.

Generative adversarial networks have very succesfully been applied to generate images 
that look indistinguishable to real images to the human eye in some case 
\cite{7550880}. 
As always in machine learning methods, the more and better data we have for 
training, the better are the results generated by generative adversarial networks.

In section \ref{sub:generative_adversarial_networks_based_communicaton_system}, we will explain in detail how generative adversarial networks can 
be applied in autoencoders for communication systems to imitiate a ``real'' channel 
response.

\section{Applying deep learning to communication systems}%
\label{sec:applying_deep_learning_to_communication_systems}

This section is the core of the report. Using the models and methods,
we defined in the earlier sections, a communication systems consisting 
only of artificial neural networks will be described here in detail. 

To begin with, the structure and methodology of these communication systems will be presented
in detail \ref{sub:artificial_neural_network_supported_end_to_end_systems}.

There are two general problems when modelling end-to-end communication systems
with artificial neural networks.

\begin{enumerate}
	\item The ``channel'' layer in the neural network (layer that models the channel response) 
	      often fails to be an accurate model of the ``real'' channel response. 
	      While the network using the ``channel'' layer shows great results, it 
	      then fails to do so when applied to a real ``channel'' response \cite{2018ISTSP..12..132D}.
      \item The receiver network is supposed to work directly on the I/Q-symbols (compare to equation \ref{eq:iq_equation} of the demodulated carrier wave and thus has problems to effectively 
	      synchronize received I/Q symbols and transmitted I/Q symbols 		when used with ``real'' channels.
\end{enumerate}

In conventional communication systems transmitter and receiver are optimized independent from each other \ref{fig:BlockCommunicationSystem} and therefore do not need to model the channel response. In artificial neural 
network supported end-to-end approaches, the system as a whole is optimized, meaning 
that parameters of the receiver affect the paramaters of 
the transmitter. Thus, when applying gradient descent \ref{sec:deep_learning_basics} 
the gradient needs to be able to ``flow'' from the output of the end of the network 
to the beginning of the network making it absolutely necessary to 
model the connection between transmitter and receiver - the channel - by another 
layer of the network (see \ref{fig:communicationSystemAsAutoencoder}).
In section \ref{sub:generative_adversarial_networks_based_communicaton_system} 
an autoencoder model implementing \emph{generative adversarial networks} to generate 
accurate channel responses to overcome the first problem is presented.
There are other approaches, such as a two-phase training strategy: First, both 
the transmitter and the receiver network are trained on a ``channel'' layer. Second, 
only the receiver is finetuned using a ``real'' channel response \cite{2018ISTSP..12..132D}. These approaches will not be further discussed in this report.

As explained in section \ref{sub:structure_of_the_communication_system}, synchronization
plays an important role in conventional communication systems in order to sample the 
carrier wave at the correct time instances so that the demodulated data is synchronus with the transmitted data. In artificial neural network supported end-to-end communication 
systems it has been shown to be quite difficult to succesfully model the ``channel layer''
in a way that the receiver network would learn to synchronize by itself \cite{2018ISTSP..12..132D}. In section \ref{sub:synchronization_problem_when_using_artificial_neural_networks} a method extending artificial neural network supported end-to-end communication systems to orthogonal frequency division multiplexing for robustness against sampling synchronization errors will be studied.

\subsection{Artificial neural network supported end-to-end communication systems}%
\label{sub:artificial_neural_network_supported_end_to_end_systems}

In this section, first the structure of the artificial neural network supported end-to-end communication systems will be explained in \ref{ssub:structure_of_artificial_neural_network_supported_end_to_end_communication_systems} using figure \ref{fig:communicationSystemAsAutoencoder}. 
Second, the learning procedure will be presented in \ref{ssub:learning_for_artificial_neural_network_supported_end_to_end_communication_systems}. 
Finally, it will be shown how to implement artificial neural network supported end-to-end communication system in practise dealing with ``real'' channel responses.

The in the following presented systems are based mainly on two papers \cite{DBLP:journals/corr/OSheaH17} and \cite{2018ISTSP..12..132D}.

\subsubsection{Structure of artificial neural network supported end-to-end communication systems}%
\label{ssub:structure_of_artificial_neural_network_supported_end_to_end_communication_systems}

Artificially neural network supported end-to-end communication systems are essentially 
always \emph{autoencoders} \ref{sub:autoencoder}, thus taking an input, mapping it to 
a compact and efficient representattion and mapping this efficient representation back 
to the original input. 

The basic structure of an autoencoder used to model a communication system in 
shown in \ref{fig:communicationSystemAsAutoencoder}. 

\begin{figure}[htpb]
	\centering
	\includegraphics[width=1.05\linewidth]{images/communicationSystemAsAutoencoder.png}
	\caption{End-to-end communication system as an autoencoder}
	\label{fig:communicationSystemAsAutoencoder}
\end{figure}
The autoencoder is divided into three parts:

\begin{itemize}
	\item Transmitter neural network
	\item Neural network embedding of the channel
	\item Receiver neural network
\end{itemize}

The autoencoder takes a one-hot embedded vector $v = \left[v_1,v_2,...v_m\right] \in \mathbb{R}^m$ as input. If $v_i = 1, v_j = 0, \forall j \ne i$, the i-th symbol $s_i$ out of the set of 
symbols $S$ with $|S|=m=2^k$ with $k$ bits is to be sent. $k$ is the number of bits 
needed to present all the $m$ different symbols.
Having defined the input, we can directly conclude that there are only $m$ possible 
different input vectors $v$ of the autoencoder.

The transmitter neural network is presented by the encoding function $f_{e, \theta_e}: v \to x, x \in \mathbb{R}^n (\text{ or } \mathbb{C}^{\frac{n}{2}})$.

In the context of communication systems, we have $n$ different channels we can use 
to send the symbol $s_i$ presented by $v_i$. Every combination of the $n$ entries in $x=\left[x_1,x_2,...,x_n\right]$ is a data point in the modulation plane (compare to \ref{sub:structure_of_the_communication_system} and \ref{fig:16QAM}). Since quatradure 
amplitude modulation (see eqaution \ref{eq:iq_equation}) uses complex numbers to 
modulate the values of $I(t) + iQ(i)$ the output layer $x$ of the neural 
network can also be considered having $\frac{n}{2}$ complex output values to 
be modulated into $\frac{n}{2}$ different carrier waves using the quadrature 
amplitude modulation. In general though $n$ ``real'' values can be modulated 
into different channels.
Due to reasons of simplicity, we will stick to $x \in \mathbb{R}^n$.

It is important to notice that the mapping $f_{e, \theta_e}: v \to x$ is deterministic, meaning
that an input $v_i$ is always mapped to the same $x_i=f_{e}(v_i)$. Since there are only 
$m$ different input vectors, there are also only $m$ different encoded vectors $\left[x_1,...,x_m\right]$ being the modulated representations of the symbols $s_1,...,s_m$.

Let's take for example the case of $n=2$. That would mean that there are two channels to 
send data. The case of having $n=2$ channels is equivalent to quadrature modulation where
the first and second channel would represent the I/Q symbols as can  be seen in \ref{fig:16QAM}

The transmitter neural network is made up of the input layer $v$ havig $m$ nodes, multiple hidden 
layers, an output layer having $n$ output nodes and the normalization output layer
$x$ also havig $n$ output nodes.
The amount and structure of the hidden layers is not too relevant and depends from 
paper to paper. Most of the time, there are no more than 3 hidden layers which have 
$m$ or less nodes \cite{2018ISTSP..12..132D}, \cite{2018arXiv180506350O}, \cite{DBLP:journals/corr/OSheaH17}.
Activation functions are normally either so-called \emph{ReLu}, being of the form 
$\text{ReLu}(x) = \begin{cases}	0, \text{ if } x<0 \\ x \end{cases}$ 
or \emph{sigmoid} activation functions, being of the 
form $\sigma(x) = \frac{1}{1+e^{-x}}$. Activation functions should be non-linear 
functions to be able to simulate complex functions. More about activation functions 
and their effects can be read in \cite{Goodfellow-et-al-2016}.

The normalization layer $x$ has some important characteristics: It makes sure that 
the output of $x$ are adapted to certain constraints of the hardware of the transmitter, being e.g. an energy constraint $||x||_2^2$, an amplitude constraint $|x_i|^2 \le a, \forall i$ or an average power constraint $\mathbb{E}(|x_i|^2) \le p, \forall i$. 
Defining one or more of these or other constraints and applying it to the normalization 
layer $x$ has huge implications on the way the autoencoder learns to map symbols $s_i$
to modulation data points $x_i$ as can be seen in \ref{fig:learnedModulation} when 
the energy constraint is applied to the normalization layer.

The neural network embedding of the channel is the so called ``channel'' layer and 
is a model of the real ``channel response'' needed for end-to-end training of the 
network. All it does is usually to add random gaussian noise to the output values $x$ of the 
transmitter neural network. Thus, it can simply be put into:
\[
	f_{c,\sigma^2}: x \to \hat{x} = x + u, u \sim N(0,\sigma^2)
\]

with $N$ representing a normal/gaussian distribution of mean $0$ and to be defined 
variance $\sigma^2$.
Since the ``channel layer'' is only a model it sometimes does not really imitate 
``real'' noise and is in general the most probable reason why autoencoder communication 
systems fail to show the same results when used in practise. 
Since more adaptive and more complex models might be needed for the ``channel layer'', \emph{O'Shea and co.} presented an approach using generative adversial networks to 
generate more complex and customized ``channel layers''. This method will 
be discussed in detail in \ref{sub:generative_adversarial_networks_based_communicaton_system}.

The receiver neural network is the decoder part of the autoencoder: $f_{\theta_d,d}: \hat{x} \to \hat{v}$ with $\hat{v} \in \mathbb{R}^n$. It is composed 
of a $n$ dimensional input layer $\hat{x}$, has multiple (normally less than 3) 
hidden layers and finally the output layer $\hat{v} \in \mathbb{R}^m$. A softmax function 
$s: \hat{v}_i\to \frac{e^{\hat{v}_i}}{\sum_{j=1}^{n} \hat{v}_j}$ is applied to every output 
node of $\hat{v}$ to normalize the output and hence make $\hat{v}$ a probability 
distribution. The received symbol $s_i$ is then found by $i = \text{argmax}_j \hat{v}_j$.
The receiver neural network essentially takes the disturbed output of the transmitter neural network and maps it back to its input. Ideally the output layer
$\hat{v}$ should be a one-hot encoded vector with $\hat{v}_i = 1$ and $\hat{v}_j = 0, \forall j \ne i$ to identify without uncertainty which symbol $s_i$ was sent. 

\subsubsection{Learning for artificial neural network supported end-to-end communication systems}%
\label{ssub:learning_for_artificial_neural_network_supported_end_to_end_communication_systems}

As explained in section \ref{sub:deep_neural_network} ``Learning'' a neural network 
essentially means to minimize a predefined loss function. It is well known that 
the more training data is available the better can the neural network be trained 
\cite{Goodfellow-et-al-2016}. The great news about modelling communication 
systems with autoencoders is that there is an unlimited supply of training data 
since the ``correct'' label of the input data is the input data itself.
So our loss function is comprised of the output of the autoencoder $\hat{v} = f_{d,	\theta_d}(f_{c, \sigma^2}(f_{e,\theta_e}(v)))$ and its input being the ``correct'' label $v$.
Neural networks using one hot encoding as label data and apply softmax to the output
layer in order to get a probabilistic distribution ($\hat{v}$) usually use the 
so-called \emph{cross entropy} as their loss function, as it is proposed in 
\cite{DBLP:journals/corr/OSheaH17}. Therefore the loss function for $N$ training
samples $v_1,...,v_N \in \mathbb{R}^n$ has the form: 

\begin{equation} \label{eq:loss}
	L = - \sum_{k=1}^{N} \sum_{j=1}^n v_{k,j} \log{\hat{v}_{k,j}} 
\end{equation}

Since the vectors $v_1,...,v_N$ are one-hot encoding with $v_{k,j} = 0 \forall j \ne i$, we can simplify \ref{eq:loss} to:

\begin{equation} \label{eq:lossShort}
	L = - \sum_{k=1}^{N} \log{\hat{v}_{k,i}}_{|i: v_{k,i} = 1}
\end{equation}

Having defined the loss function, the gradient can be computed to update the 
parameters of both the encoder and the decoder network $\theta_e,\theta_d$ using 
gradient descent: 
\[
	\theta_e \leftarrow \theta_e - \alpha \frac{\partial L}{\partial \theta_e}
\]
and 
\[
	\theta_d \leftarrow \theta_d - \alpha \frac{\partial L}{\partial \theta_e}
\]

Gradient descent follows the idea that in order to reach a local optimum, one 
just calculates the gradient for every dimension and follows the gradient until 
a local minimum of the loss funciton $L$ is reached. Whereas $\frac{\partial L}{\partial \theta_e}$ states the direction to reach the local optimum, $\alpha$ is a 
constant factor stating ``how much to go in this direction''. $\theta_e$ and 
$\theta_d$ represent the whole space of trainable parameters for both the encoder and 
decoder neural networks, namely the weights between the different layers \ref{sub:deep_neural_network}. Therefore the above defined update rules have to be performed 
individually for every single parameter is $\theta_e$ and $\theta_d$ by calculating 
the respective gradients. Having $|\theta_e| + |\theta_d|$ trainable parameters 
means that we also need to calculate $|\theta_e| + |\theta_d|$ different gradients 
for every training sample $(v_k,\hat{v}_k)$. More details, also about other 
hyper training parameters, such as regularization, batch size, ... can 
be read upon in \cite{Goodfellow-et-al-2016}.
One should keep in mind that $\sigma^2$ in $f_{c,\sigma^2}$ is not a trainable 
parameter but needs to be chosen by the architect of the autoencoder so that the 
``channel layer'' best represents the ``real'' channel response.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.4\linewidth]{images/learnedModulation.png}
	\caption{Learned outputs of transmitter neural network output layer $x$ of all $m=16$ possible inputs and for $n=2$ channels. The x-Axis is presenting the values of the first output node in $x$ and the y-Axis the second}
	\label{fig:learnedModulation}
\end{figure}

It can be noticed that the autoencoder is able to 
learn efficent and robust modulation schemes which in case of figure 
\ref{fig:learnedModulation} was leaned for $n=2$ and $m=16 $ and clearly corresponds to the well known \emph{16-QAM} modulation scheme. As stated in \cite{DBLP:journals/corr/OSheaH17} the learned 
modulation arrangement strongly depends on the constraints put on the normalization 
layer in the transmitter neural network.

\subsubsection{Applying artificial neural network supported end-to-end communication systems in ``real'' environment}%
\label{ssub:applying_artificial_neural_network_supported_end_to_end_communication_systems_in_real_environment}

Having trained both the transmitter and the receiver neural networks, the real 
testing will take place on actual hardware and a ``real'' channel. 
The transmitter and receiver neural networks have to be implemented at the
transmitter and the receiver respectively. 
At the transmitter, the values for every of the $n$ channel of the output layer $x$ 
will be modulated into a carrier wave of the ``real'' channel. 
At the receiver the carrier wave is sampled for the $n$ channels and the sampled $n$
sampled values are plugged into the receiver network to be classified to one of 
m code symbols. As mentioned before \emph{synchronization} plays an important role 
here and might lead to problems if not taken care of. Section \ref{sub:synchronization_problem_when_using_artificial_neural_networks} is commited to this.
If the results using the ``real channel'' are not at all comparable to the expected 
results, the modelled ``channel layer'' has to be rethought and might not at all 
be an accurate model of the ``real channel''.

\subsection{Generative Adversarial Networks to model the channel}%
\label{sub:generative_adversarial_networks_based_communicaton_system}

As already stated, one of the major problems of the basic autoencoder as stated in 
\ref{sub:artificial_neural_network_supported_end_to_end_systems} is that the 
``layer channel'' fails to imitate of a real world system ``including the effects induced
by digital conversion, analog RF hardware, and other sources
of distortions and impairments'' \cite{2018arXiv180303145O}. 
The analytical expression within the ``layer channel'' must be able to capture all of
these effects in a differentiable way suitable for the backpropagation algorithm \ref{sub:deep_neural_network}.

One idea to do so, is to apply a system similar to generative adversial networks with 
a neural network analogue to the discriminator network \ref{sub:generative_adversarial_networks} $h_{1,\theta_h}: x \to \hat{y}$ that learns to approximate a ``real'' channel by comparing its 
results to one $h_0:x \to y$ and a autoencoder as introduced in \ref{sub:artificial_neural_network_supported_end_to_end_systems} having a transmitter neural network 
$f_{\theta_f}:s \to x$ and a receiver neural network $g_{\theta_g}:\hat{y} \to \hat{s}$ taking 
the role of the \emph{generator neural network} by learning better coding and 
encoding schemes using the parameters of $h_{1,\theta_h}$.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=1\linewidth]{images/generativeAdvAutoencoder.png}
	\caption{Generative adversial network learning a communication system}
	\label{fig:generativeAdvAutoencoder}
\end{figure}

In Figure \ref{fig:generativeAdvAutoencoder}, such a system can be seen.
It can be seen that the network to approximate a ``real'' channel is made up of 
multiple layers each having the non-linear \emph{ReLu} activation functions. This 
increased depth of the ``channel layer'' or by now it should better be called the 
``channel neural network'' allows for the ability to learn much more complex 
real world channel behavior.

The loss function for $h_{1,\theta_h}$ is defined as a \emph{mean square error} loss 
function for $N$ training samples: 
\[
	L_0: \sum_{k=1}^N || y_k - \hat{y}_k ||_2^2 = || h_{1, \theta_h}(f_{\theta_f}(s_k)) - h_0(f_{\theta_f}(s_k)) ||_2^2 
\]

The loss function for $f_{\theta_f},g_{\theta_g}$ is defined as before in \ref{sub:artificial_neural_network_supported_end_to_end_systems} as the cross entropy loss function:
\[
	L_1 = - \sum_{k=1}^{N} \log{\hat{s}_{k,i}}_{|i: s_{k,i} = 1} = 
	- \sum_{k=1}^{N} \log{g_{\theta_g}(h_{1,\theta_h}(f_{\theta_f}(s_k)))_i}_{|i: s_{k,i} = 1}
\]

The following pseudo algorithm summarizes the training procedure for the 
alternating training.

\vspace{1em}

\begin{algorithm}[H]
	\DontPrintSemicolon
	$\theta_f,\theta_h,\theta_g \leftarrow $ random initial weights\;
	\For{epoch in epochs}{
		\For{step in steps}{
			\For{$k \leftarrow 1$ \KwTo $N$}{
				$s_k \leftarrow $ random training samples \;
				$y_k \leftarrow h_{1, \theta_h}(f_{\theta_f}(s_k))$ \;
				$\hat{y}_k \leftarrow h_0(f_{\theta_f}(s_k))$ \;	
			}
			$ \theta_h \leftarrow \theta_h - \alpha_0 \frac{\partial L_0}{\partial \theta_h} $ \;
		}
		\For{step in steps}{
			\For{$k \leftarrow 1$ \KwTo $N$}{
				$s_k \leftarrow $ random training samples \;
				$\hat{s}_k \leftarrow g_{\theta_g}(h_{1,\theta_h}(f_{\theta_f}(s_k)))$ \;
			}
			$ \theta_f \leftarrow \theta_f - \alpha_0 \frac{\partial L_1}{\partial \theta_f} $ \;
			$ \theta_g \leftarrow \theta_g - \alpha_0 \frac{\partial L_1}{\partial \theta_g} $ \;
		}
	}
	\caption{System using Generative Adversial Networks Training Procedure}
\end{algorithm}

\vspace{1em}

It can be seen that the networks $h_{1,\theta_h}$ and $f_{\theta_f},g_{\theta_g}$ are 
optimized for a certain amount of \emph{steps} each in an alternating fashion. 
First the ``channel network'' $h_{1,\theta_h}$  tries to imitiate the ``real'' channel response. 
Having a good approximation, the autoencoder networks $f_{\theta_f},g_{\theta_g}$ are trained on the ``channel network'' $h_{1,\theta_h}$ to create more efficient encodings of 
the symbols $s_k$. 
Having learned a new encoding scheme, the ``real'' channel response has changed as well, 
so that the $h_{1,\theta_h}$ needs to be relearned and so on...
This training procedure will eventually lead to smaller and smaller changes and converges.

In the papers \cite{2018arXiv180506350O},\cite{2018arXiv180303145O}, it is shown that the system using generative adversial networks 
is able to adapt to very different ``real'' channels and learns very efficient 
encoding schemes for each of them.

\subsection{Synchronization using artificial neural networks}%
\label{sub:synchronization_problem_when_using_artificial_neural_networks}

The systems presented so far in sections \ref{sub:artificial_neural_network_supported_end_to_end_systems} and \ref{sub:generative_adversarial_networks_based_communicaton_system} 
did not cope with the problem of unsynchronized electrical oscilators. 
Unsynchronized oscilators lead to a frequency offset and carrier offset forcing the 
receiver neural network to figure out the offsets of the start and end of a message because it works directly with the sampled values of the carrier wave \cite{synch1}.
Especially, when using the quadrature amplitude modulation scheme \ref{eq:iq_equation}, the exact phase of the carrier wave is needed for demodulation. Therefore, the issue 
of carrier wave synchronization must be handled somehow in quadrature amplitude 
modulation systems.

In the following, an approach from the paper \cite{synch1} tackling the problem 
of unsynchronized electrical oscilator will be presented.

The idea of the system is based on orthogonal frequency-division multiplexing. Orthogonal frequency-division multiplexing will not be discussed in detail here, 
but can be read upon in \cite{387096}.

The system of section \ref{sub:artificial_neural_network_supported_end_to_end_systems} is extended by two blocks on the transmitter side (``IFFT'' and ``CP Add'') and two blocks on the receiver side (``CP Sync'' and ``FFT''), whereas the transmitter neural network is labeled as ``AETX'' and the receiver 
neural network is labeled as ``AERX'' as can be seen in figure \ref{fig:synchBlock}.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.8\linewidth]{images/synchBlock.png}
	\caption{Autoencoder system with orthogonal frequency-division multiplexing extension}
	\label{fig:synchBlock}
\end{figure}

Assuming that the autoencoder has $n$ channels, $n/2$ complex I/Q symbols can be used to encode one symbol $s$ to $x$. 
Analogue to orthogonal frequency-division multiplexing, multiple encoded messages 
$x$ are first transformed via the inverse discrete fourier transform. We define $w_{FFT}$ as the number of messages $x$ 
that are encoded together. 
Having these messages $X = (x_1, ..., x_{w_{FFT}}) \in \mathbb{C}^{\frac{n}{2} \times w_{FFT}}$, the inverse discrete fourier 
transform can be applied over the messages:
\[
	X_{OFDM} = \text{IFFT}(X) \in \mathbb{C}^{\frac{n}{2} \times w_{FFT}}
\]
In order to be more robust against synchronization errors, a so-called cyclic prefix
is then added at the beginning of each message $x_i, \forall i \in \{1,...,w_{FFT}\}$
for every two messages. Finally, we derive $X_{OFDM} \to X_{OFDM, CP} \in \mathbb{C}^{\frac{n}{2} \times w_{FFT}}$ and $X_{OFDM} \to X_{OFDM, CP} \in \mathbb{C}^{\frac{n+2}{2} \times w_{FFT}}$ at every other message.
A more visual representation is figure \ref{fig:ifft_synch}.

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.65\linewidth]{images/ifft_synch.png}
	\caption{Over time autoencoder with ``IFFT''}
	\label{fig:ifft_synch}
\end{figure}

$X_{OFDM, CP}$ is then sent over the channel to the receiver. 
At the receiver the cyclic prefix is used for frame synchronization through
autocorrelation, also
called peak detection (synchronization by finding the alignment between the received 
signal and the known cyclic prefix yielding the highest correlation).
After synchronization the cyclic prefix can be deleted, which is easy 
since through autocorrelation it is known exactly where it is and the ``inverse 
inverse discrete fourier transform'' being the discrete fourier transform is applied
to recover encoded message in the time-domain again.
At last, the receiver neural network is used to recover the sent symbol $s$.

This procedure helps greatly to reduce synchronization errors by 
using basic methods from conventional communication system design.

\section{Conclusion} % (fold)
\label{sec:conclusion}

It is very difficult to compare the performance of conventional communication 
systems to those applying deep learning methods, such as autoencoders \ref{sec:applying_deep_learning_to_communication_systems} because of the completely different 
structure and generalization possibilities. 
Autoencoder systems such as those presented in \ref{sec:applying_deep_learning_to_communication_systems} need a predefined amount of channels $n$ and set of symbols 
$M$ for the layer dimensions to be trained to build efficient modulation schemes. 
Conventional systems on the other hand are much more flexible and can directly 
be applied without having to learn anything to varying size of channels $n$ and 
set of symbols $M$.
In addition, autoencoder systems are trained on ``channel'' models that often only 
add gaussian noise to the transmitted message and thus are also tested on 
only these kinds of channels which is not really realistic. 
Even though the papers \cite{2018arXiv180303145O}, \cite{synch1}, \cite{DBLP:journals/corr/OSheaH17} do some performance comparisons using the \emph{source-to-noise ratio}
for example, the question whether these comparisons are realistic remains open.

For once, it has certainly been shown that autoencoder systems are 
able to learn efficient ways to encode symbols $s$ \ref{fig:learnedModulation}.
Also, we saw that some methods, such as using generative adversial networks to imitate real 
channel responses, can make autoencoder system applicable to more general conditions.

All in all it has to be said that research about applying deep learning methods 
for the physical layer is still in its beginnings and will certainly yield 
more sophisticated methods in the years to come.

% section conclusion (end)
\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{vonPlaten_report}

\end{document}
